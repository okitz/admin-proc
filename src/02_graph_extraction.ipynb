{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# グラフ抽出 (Graph Extraction)\n",
                "\n",
                "収集したテキストデータから手続きの依存関係グラフを抽出する。\n",
                "LLMを使用してテキストを解析し、JSON形式のグラフデータに変換する。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import glob\n",
                "import asyncio\n",
                "from typing import List, Optional\n",
                "from enum import Enum\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "from langchain_ollama import ChatOllama\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "import config\n",
                "\n",
                "# 設定\n",
                "DATA_DIR = \"data/raw_text\"\n",
                "OUTPUT_DIR = \"data/processed_graph\"\n",
                "PROMPT_FILE = \"prompt.md\"\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "# LLM設定\n",
                "# MODEL_NAME = \"gemma3:12b\"\n",
                "MODEL_NAME = \"qwen3-vl:8b\"\n",
                "BASE_URL = \"http://localhost:11434\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ActionType(str, Enum):\n",
                "    Physical_Go = \"Physical_Go\"\n",
                "    Physical_Mail = \"Physical_Mail\"\n",
                "    Physical_Copy = \"Physical_Copy\"\n",
                "    Physical_Print = \"Physical_Print\"\n",
                "    Physical_Fill = \"Physical_Fill\"\n",
                "    Physical_Attach = \"Physical_Attach\"\n",
                "    External_Acquire = \"External_Acquire\"\n",
                "    Digital_Input = \"Digital_Input\"\n",
                "    Digital_Auth = \"Digital_Auth\"\n",
                "    Digital_Upload = \"Digital_Upload\"\n",
                "    Digital_Capture = \"Digital_Capture\"\n",
                "    Digital_Submit = \"Digital_Submit\"\n",
                "    Wait_Process = \"Wait_Process\"\n",
                "    No_Action = \"No_Action\"\n",
                "\n",
                "class ActionCategory(str, Enum):\n",
                "    Work = \"Work\"\n",
                "    Move = \"Move\"\n",
                "    Wait = \"Wait\"\n",
                "\n",
                "class GraphEdge(BaseModel):\n",
                "    source: str = Field(description=\"The starting point or prerequisite of the action\")\n",
                "    target: str = Field(description=\"The result or next step of the action\")\n",
                "    action: str = Field(description=\"The specific action taken\")\n",
                "    type: ActionType = Field(description=\"The type of cost/action\")\n",
                "    category: ActionCategory = Field(description=\"The subject/category of the action\")\n",
                "\n",
                "class GraphData(BaseModel):\n",
                "    analog: List[GraphEdge] = Field(description=\"Dependency graph for analog application\")\n",
                "    digital: List[GraphEdge] = Field(description=\"Dependency graph for digital application\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize LLM\n",
                "llm = ChatOllama(\n",
                "    model=MODEL_NAME,\n",
                "    base_url=BASE_URL,\n",
                "    temperature=0.1\n",
                ")\n",
                "\n",
                "# Structured Output\n",
                "structured_llm = llm.with_structured_output(GraphData)\n",
                "\n",
                "def create_chain(prompt_path: str):\n",
                "    with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
                "        prompt_text = f.read()\n",
                "    \n",
                "    # Create Prompt Template\n",
                "    # prompt.md contains {input_homepage} and {input_digital}\n",
                "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
                "    \n",
                "    # Create Chain\n",
                "    chain = prompt | structured_llm\n",
                "    return chain\n",
                "\n",
                "async def extract_graph(chain, homepage_text, digital_text):\n",
                "    try:\n",
                "        result = await chain.ainvoke({\n",
                "            \"input_homepage\": homepage_text,\n",
                "            \"input_digital\": digital_text\n",
                "        })\n",
                "        return result\n",
                "    except Exception as e:\n",
                "        print(f\"Error during extraction: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing 文京区 (13105)...\n"
                    ]
                },
                {
                    "ename": "CancelledError",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/langchain_ollama/chat_models.py:986\u001b[0m, in \u001b[0;36mChatOllama._achat_stream_with_aggregation\u001b[0;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aiterate_over_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/langchain_ollama/chat_models.py:1126\u001b[0m, in \u001b[0;36mChatOllama._aiterate_over_stream\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m reasoning \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreasoning)\n\u001b[0;32m-> 1126\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acreate_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/langchain_ollama/chat_models.py:932\u001b[0m, in \u001b[0;36mChatOllama._acreate_chat_stream\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_client\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_params):\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m part\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/ollama/_client.py:759\u001b[0m, in \u001b[0;36mAsyncClient._request.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    757\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 759\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39maiter_lines():\n\u001b[1;32m    760\u001b[0m   part \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpx/_models.py:1031\u001b[0m, in \u001b[0;36mResponse.aiter_lines\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m-> 1031\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maiter_text():\n\u001b[1;32m   1032\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m decoder\u001b[38;5;241m.\u001b[39mdecode(text):\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpx/_models.py:1018\u001b[0m, in \u001b[0;36mResponse.aiter_text\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m-> 1018\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m byte_content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maiter_bytes():\n\u001b[1;32m   1019\u001b[0m         text_content \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(byte_content)\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpx/_models.py:997\u001b[0m, in \u001b[0;36mResponse.aiter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 997\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maiter_raw():\n\u001b[1;32m    998\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpx/_models.py:1055\u001b[0m, in \u001b[0;36mResponse.aiter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m-> 1055\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m   1056\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpx/_client.py:176\u001b[0m, in \u001b[0;36mBoundAsyncStream.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__aiter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAsyncIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:271\u001b[0m, in \u001b[0;36mAsyncResponseStream.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m part\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpcore/_async/connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maclose()\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpcore/_async/connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m part\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpcore/_async/http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maclose()\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpcore/_async/http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpcore/_async/http11.py:203\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpcore/_async/http11.py:217\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/httpcore/_backends/anyio.py:35\u001b[0m, in \u001b[0;36mAnyIOStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39mreceive(max_bytes\u001b[38;5;241m=\u001b[39mmax_bytes)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mEndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py:1263\u001b[0m, in \u001b[0;36mSocketStream.receive\u001b[0;34m(self, max_bytes)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mresume_reading()\n\u001b[0;32m-> 1263\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mpause_reading()\n",
                        "File \u001b[0;32m/usr/lib/python3.10/asyncio/locks.py:214\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                        "\u001b[0;31mCancelledError\u001b[0m: ",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:5547\u001b[0m, in \u001b[0;36mRunnableBindingBase.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5540\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5541\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m   5542\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5545\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5546\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m   5548\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5549\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5550\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5551\u001b[0m     )\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:408\u001b[0m, in \u001b[0;36mBaseChatModel.ainvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 408\u001b[0m llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[1;32m    409\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    410\u001b[0m     stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    411\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    412\u001b[0m     tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    413\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    414\u001b[0m     run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    415\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    417\u001b[0m )\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m, cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m, llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    420\u001b[0m )\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1115\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m-> 1115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[1;32m   1116\u001b[0m     prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1117\u001b[0m )\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1035\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m input_messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1033\u001b[0m     _normalize_messages(message_list) \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m   1034\u001b[0m ]\n\u001b[0;32m-> 1035\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate_with_cache(\n\u001b[1;32m   1038\u001b[0m             m,\n\u001b[1;32m   1039\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   1040\u001b[0m             run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1041\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1042\u001b[0m         )\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages)\n\u001b[1;32m   1044\u001b[0m     ],\n\u001b[1;32m   1045\u001b[0m     return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1046\u001b[0m )\n\u001b[1;32m   1047\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n",
                        "\u001b[0;31mCancelledError\u001b[0m: ",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[17], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  -> Failed to extract graph for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
                        "Cell \u001b[0;32mIn[17], line 30\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     digital_text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# グラフ抽出\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m graph_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m extract_graph(chain, general_text, digital_text)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph_data:\n\u001b[1;32m     33\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "Cell \u001b[0;32mIn[16], line 25\u001b[0m, in \u001b[0;36mextract_graph\u001b[0;34m(chain, general_text, digital_text)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_graph\u001b[39m(chain, general_text, digital_text):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mainvoke({\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_general\u001b[39m\u001b[38;5;124m\"\u001b[39m: general_text,\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_digital\u001b[39m\u001b[38;5;124m\"\u001b[39m: digital_text\n\u001b[1;32m     28\u001b[0m         })\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "File \u001b[0;32m~/eeic_lectures/3a/superD/admin-proc/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3169\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3167\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3168\u001b[0m                 part \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(step\u001b[38;5;241m.\u001b[39mainvoke, input_, config)\n\u001b[0;32m-> 3169\u001b[0m             input_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(part(), context, create_task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3170\u001b[0m     \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "\u001b[0;31mCancelledError\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "async def main():\n",
                "    chain = create_chain(PROMPT_FILE)\n",
                "    \n",
                "    for city in config.TARGET_CITIES:\n",
                "        city_id = city[\"id\"]\n",
                "        city_name = city[\"name\"]\n",
                "        print(f\"Processing {city_name} ({city_id})...\")\n",
                "        \n",
                "        # ファイルの検索\n",
                "        homepage_files = glob.glob(os.path.join(DATA_DIR, f\"{city_id}_homepage*.txt\"))\n",
                "        digital_files = glob.glob(os.path.join(DATA_DIR, f\"{city_id}_digital*.txt\"))\n",
                "        \n",
                "        if not homepage_files or not digital_files:\n",
                "            print(f\"  -> Missing files for {city_name}. Skipping.\")\n",
                "            continue\n",
                "            \n",
                "        with open(homepage_files[0], \"r\", encoding=\"utf-8\") as f:\n",
                "            homepage_text = f.read()\n",
                "        with open(digital_files[0], \"r\", encoding=\"utf-8\") as f:\n",
                "            digital_text = f.read()\n",
                "            \n",
                "        # グラフ抽出\n",
                "        graph_data = await extract_graph(chain, homepage_text, digital_text)\n",
                "        \n",
                "        if graph_data:\n",
                "            output_path = os.path.join(OUTPUT_DIR, f\"{city_id}.json\")\n",
                "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
                "                json.dump(graph_data.model_dump(), f, indent=2, ensure_ascii=False)\n",
                "            print(f\"  -> Saved to {output_path}\")\n",
                "        else:\n",
                "            print(f\"  -> Failed to extract graph for {city_name}\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    await main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "admin-proc",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
